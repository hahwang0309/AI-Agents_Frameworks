import streamlit as st
from main import graph, State
from dotenv import load_dotenv
import os
from langchain_core.messages import AIMessage, ToolMessage

# Load environment variables
load_dotenv()

# API í‚¤ ê²€ì¦
anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
tavily_api_key = os.getenv('TAVILY_API_KEY')

if not anthropic_api_key:
    st.error("ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()
if not tavily_api_key:
    st.error("TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="LangGraph ì±—ë´‡", page_icon="ğŸ’¬")
st.title("LangGraph ì±—ë´‡")

def extract_search_results_from_messages(messages):
    """ë©”ì‹œì§€ì—ì„œ Tavily ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¶”ì¶œ"""
    search_results = []
    
    for message in messages:
        # ToolMessageì—ì„œ Tavily ê²€ìƒ‰ ê²°ê³¼ ì°¾ê¸°
        if isinstance(message, ToolMessage):
            try:
                content = message.content
                # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš° JSON íŒŒì‹± ì‹œë„
                if isinstance(content, str):
                    import json
                    results = json.loads(content)
                    if isinstance(results, list):
                        search_results.extend(results)
                # contentê°€ ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                elif isinstance(content, list):
                    search_results.extend(content)
            except (json.JSONDecodeError, TypeError):
                continue
        
        # AIMessageì—ì„œ tool_callsê°€ ìˆëŠ” ê²½ìš°ë„ í™•ì¸
        elif isinstance(message, AIMessage) and hasattr(message, 'tool_calls'):
            tool_calls = getattr(message, 'tool_calls', [])
            for tool_call in tool_calls:
                if hasattr(tool_call, 'name') and 'tavily' in tool_call.name.lower():
                    # tool_callì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ ì‹œë„
                    pass
    
    return search_results

def format_search_sources(search_results):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì†ŒìŠ¤ ë§í¬ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if not search_results:
        return []
    
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê´€ë ¨ì„± ì ìˆ˜(score) ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    sorted_results = sorted(
        search_results,
        key=lambda x: x.get('score', 0),
        reverse=True  # ë†’ì€ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
    )
    
    # ê´€ë ¨ì„± ì ìˆ˜ê°€ 0.5 ì´ìƒì¸ ê²°ê³¼ë§Œ í•„í„°ë§
    filtered_results = [
        result for result in sorted_results 
        if result.get('score', 0) >= 0.5
    ]
    
    # ìƒìœ„ 10ê°œ ê²°ê³¼ë§Œ ì„ íƒ
    top_results = filtered_results[:10]
    
    sources = []
    for result in top_results:
        if isinstance(result, dict):
            title = result.get('title', '')
            url = result.get('url', '')
            score = result.get('score', 0)
            
            if title and url:
                # ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ
                relevance = f"{score * 100:.1f}%"
                sources.append(f"[{title}]({url}) (ê´€ë ¨ì„±: {relevance})")
    
    return sources

def get_final_response_and_sources(response):
    """LangGraph ì‘ë‹µì—ì„œ ìµœì¢… ë‹µë³€ê³¼ ê²€ìƒ‰ ì†ŒìŠ¤ë¥¼ ì¶”ì¶œ"""
    if not isinstance(response, dict) or "messages" not in response:
        return str(response), []
    
    messages = response["messages"]
    
    # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
    search_results = extract_search_results_from_messages(messages)
    sources = format_search_sources(search_results)
    
    # ìµœì¢… AI ì‘ë‹µ ì°¾ê¸°
    final_answer = ""
    for message in reversed(messages):
        if isinstance(message, AIMessage):
            content = message.content
            # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì˜ˆ: [{'text': '...', 'type': 'text'}])
            if isinstance(content, list):
                for item in content:
                    if isinstance(item, dict) and item.get('type') == 'text':
                        final_answer = item.get('text', '')
                        break
                if final_answer:
                    break
            # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš°
            elif isinstance(content, str):
                final_answer = content
                break
    
    return final_answer, sources

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "thread_id" not in st.session_state:
    st.session_state.thread_id = "1"

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # ì†ŒìŠ¤ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
        if message.get("sources"):
            st.markdown("---")
            st.markdown("### ğŸ“š ì°¸ê³  ìë£Œ")
            for source in message["sources"]:
                st.markdown(f"â€¢ {source}")

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì±—ë´‡ ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        try:
            with st.spinner("ìƒê° ì¤‘..."):
                # LangGraphë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±
                config = {"configurable": {"thread_id": st.session_state.thread_id}}
                
                # ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í¬í•¨í•œ ë©”ì‹œì§€ ìƒì„±
                messages = []
                for msg in st.session_state.messages:
                    if msg["role"] == "user":
                        messages.append(("user", msg["content"]))
                    elif msg["role"] == "assistant":
                        messages.append(("assistant", msg["content"]))
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„±
                response_container = st.empty()
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
                final_answer = ""
                all_sources = []  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½í•˜ì—¬ ìˆœì„œ ìœ ì§€
                
                for event in graph.stream({"messages": messages}, config):
                    for value in event.values():
                        if "messages" in value and value["messages"]:
                            last_message = value["messages"][-1]
                            
                            # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
                            if isinstance(last_message, ToolMessage):
                                search_results = extract_search_results_from_messages([last_message])
                                new_sources = format_search_sources(search_results)
                                # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€
                                for source in new_sources:
                                    if source not in all_sources:
                                        all_sources.append(source)
                            
                            # AI ì‘ë‹µ ì²˜ë¦¬
                            elif isinstance(last_message, AIMessage):
                                if isinstance(last_message.content, str):
                                    final_answer = last_message.content
                                elif isinstance(last_message.content, list):
                                    for item in last_message.content:
                                        if isinstance(item, dict) and item.get('type') == 'text':
                                            final_answer = item.get('text', '')
                                            break
                                
                                # ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µ ì—…ë°ì´íŠ¸
                                if final_answer:
                                    response_container.markdown(final_answer)
                
                # ëª¨ë“  ì†ŒìŠ¤ë¥¼ í•œ ë²ˆì— í‘œì‹œ
                if all_sources:
                    st.markdown("---")
                    st.markdown("### ğŸ“š ì°¸ê³  ìë£Œ")
                    for source in all_sources:  # ì´ë¯¸ ì •ë ¬ëœ ìˆœì„œë¡œ í‘œì‹œ
                        st.markdown(f"â€¢ {source}")
                
                # ìµœì¢… ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": final_answer or "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": all_sources
                })
                
        except Exception as e:
            error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.error(error_msg)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": error_msg,
                "sources": []
            })

# ì‚¬ì´ë“œë°”ì— ë””ë²„ê¹… ì •ë³´ (ì„ íƒì )
with st.sidebar:
    st.header("ë””ë²„ê¹… ì •ë³´")
    if st.checkbox("ì‘ë‹µ êµ¬ì¡° ë³´ê¸°"):
        if st.session_state.messages:
            st.json({
                "total_messages": len(st.session_state.messages),
                "thread_id": st.session_state.thread_id
            })
    
    if st.checkbox("ìƒì„¸ ë””ë²„ê¹…"):
        st.write("ë§ˆì§€ë§‰ LangGraph ì‘ë‹µ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ë ¤ë©´ ì´ ì˜µì…˜ì„ ì²´í¬í•˜ì„¸ìš”.")
    
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.thread_id = str(int(st.session_state.thread_id) + 1)  # ìƒˆë¡œìš´ thread_id ìƒì„±
        st.rerun()